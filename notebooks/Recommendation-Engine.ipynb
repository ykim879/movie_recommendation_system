{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    " \n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def get_counts_and_averages(ID_and_ratings_tuple):\n",
    "    nratings = len(ID_and_ratings_tuple[1])\n",
    "    return ID_and_ratings_tuple[0], (nratings, float(sum(x for x in ID_and_ratings_tuple[1]))/nratings)\n",
    "\n",
    "\n",
    "class RecommendationEngine:\n",
    "    \"\"\"A movie recommendation engine\n",
    "    \"\"\"\n",
    " \n",
    "    def __count_and_average_ratings(self):\n",
    "        \"\"\"Updates the movies ratings counts from \n",
    "        the current data self.ratings_RDD\n",
    "        \"\"\"\n",
    "        logger.info(\"Counting movie ratings...\")\n",
    "        movie_ID_with_ratings_RDD = self.ratings_RDD.map(lambda x: (x[1], x[2])).groupByKey()\n",
    "        movie_ID_with_avg_ratings_RDD = movie_ID_with_ratings_RDD.map(get_counts_and_averages)\n",
    "        self.movies_rating_counts_RDD = movie_ID_with_avg_ratings_RDD.map(lambda x: (x[0], x[1][0]))\n",
    " \n",
    " \n",
    "    def __train_model(self):\n",
    "        \"\"\"Train the ALS model with the current dataset\n",
    "        \"\"\"\n",
    "        logger.info(\"Training the ALS model...\")\n",
    "        ratingforals = self.ratings_RDD.toDF()\n",
    "        (training, test) = ratingforals.randomSplit([0.5, 0.5])\n",
    "        # Build the recommendation model using ALS on the training data\n",
    "        # Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "        # c\n",
    "        als = ALS(maxIter=3, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", \n",
    "                  coldStartStrategy=\"drop\")\n",
    "        self.model = als.fit(training)\n",
    "\n",
    "        # Evaluate the model by computing the RMSE on the test data\n",
    "        predictions = self.model.transform(test)\n",
    "        evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                        predictionCol=\"prediction\")\n",
    "        rmse = evaluator.evaluate(predictions)\n",
    "        logger.info(\"Root-mean-square error = \" + str(rmse))\n",
    "        logger.info(\"ALS model built!\")\n",
    " \n",
    " \n",
    "    def __init__(self, sc, movie, ratings):\n",
    "        \"\"\"Init the recommendation engine given a Spark context and a dataset path\n",
    "        \"\"\"\n",
    " \n",
    "        logger.info(\"Starting up the Recommendation Engine: \")\n",
    " \n",
    "        self.sc = sc\n",
    " \n",
    "        # Load ratings data for later use\n",
    "        \n",
    "        #logger.info(\"Loading Ratings data...\")\n",
    "        #ratings_file_path = os.path.join(dataset_path, 'ratings.csv')\n",
    "        #ratings_raw_RDD = self.sc.textFile(ratings_file_path)\n",
    "        #ratings_raw_data_header = ratings_raw_RDD.take(1)[0]\n",
    "        #self.ratings_RDD = ratings_raw_RDD.filter(lambda line: line!=ratings_raw_data_header)\\\n",
    "        #    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),int(tokens[1]),float(tokens[2]))).cache()\n",
    "        # Load movies data for later use\n",
    "        #logger.info(\"Loading Movies data...\")\n",
    "        #movies_file_path = os.path.join(dataset_path, 'movies.csv')\n",
    "        #movies_raw_RDD = self.sc.textFile(movies_file_path)\n",
    "        #movies_raw_data_header = movies_raw_RDD.take(1)[0]\n",
    "        #self.movies_RDD = movies_raw_RDD.filter(lambda line: line!=movies_raw_data_header)\\\n",
    "        #    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),tokens[1],tokens[2])).cache()\n",
    "        # Pre-calculate movies ratings counts\n",
    "        self.movies_RDD = movie.rdd\n",
    "        self.movies_titles_RDD = self.movies_RDD.map(lambda x: (int(x[0]),x[1])).cache()\n",
    "\n",
    "        self.ratings_RDD = ratings.rdd\n",
    "        self.__count_and_average_ratings()\n",
    " \n",
    "        # Train the model\n",
    "        #self.rank = 8\n",
    "        #self.seed = 13\n",
    "        #self.iterations = 10\n",
    "        #self.regularization_parameter = 0.1\n",
    "        self.__train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ratings(self, ratings):\n",
    "    \"\"\"Add additional movie ratings in the format (user_id, movie_id, rating)\n",
    "    \"\"\"\n",
    "    # Convert ratings to an RDD\n",
    "    new_ratings_RDD = self.sc.parallelize(ratings)\n",
    "    # Add new ratings to the existing ones\n",
    "    self.ratings_RDD = self.ratings_RDD.union(new_ratings_RDD)\n",
    "    # Re-compute movie ratings count\n",
    "    self.__count_and_average_ratings()\n",
    "    # Re-train the ALS model with the new ratings\n",
    "    self.__train_model()\n",
    "\n",
    "    return ratings\n",
    "\n",
    "# Attach the function to a class method\n",
    "RecommendationEngine.add_ratings = add_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __predict_ratings(self, user_and_movie_RDD):\n",
    "    \"\"\"Gets predictions for a given (userID, movieID) formatted RDD\n",
    "    Returns: an RDD with format (movieTitle, movieRating, numRatings)\n",
    "\n",
    "    predicted_RDD = self.model.predictAll(user_and_movie_RDD)\n",
    "    predicted_rating_RDD = predicted_RDD.map(lambda x: (x.product, x.rating))\n",
    "    predicted_rating_title_and_count_RDD = \\\n",
    "        predicted_rating_RDD.join(self.movies_titles_RDD).join(self.movies_rating_counts_RDD)\n",
    "    predicted_rating_title_and_count_RDD = \\\n",
    "        predicted_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))\n",
    "\n",
    "    return predicted_rating_title_and_count_RDD\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "def get_top_ratings(self, user_id, movies_count):\n",
    "    \"\"\"Recommends up to movies_count top unrated movies to user_id\n",
    "    \"\"\"\n",
    "    # Get pairs of (userID, movieID) for user_id unrated movies\n",
    "    #user_unrated_movies_RDD = self.ratings_RDD.filter(lambda rating: not rating[1]==user_id).map(lambda x: (user_id, x[1]))\n",
    "    # Get predicted ratings\n",
    "    #ratings = self.__predict_ratings(user_unrated_movies_RDD).filter(lambda r: r[2]>=25).takeOrdered(movies_count, key=lambda x: -x[1])\n",
    "    userRecs = self.model.recommendForAllUsers(movies_count)\n",
    "    ratings\n",
    "    return ratings\n",
    "\n",
    "# Attach the functions to class methods\n",
    "RecommendationEngine.__predict_ratings = __predict_ratings\n",
    "RecommendationEngine.get_top_ratings = get_top_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings_for_movie_ids(self, user_id, movie_ids):\n",
    "    \"\"\"Given a user_id and a list of movie_ids, predict ratings for them \n",
    "    \"\"\"\n",
    "    requested_movies_RDD = self.sc.parallelize(movie_ids).map(lambda x: (user_id, x))\n",
    "    # Get predicted ratings\n",
    "    ratings = self.__predict_ratings(requested_movies_RDD).collect()\n",
    "\n",
    "    return ratings\n",
    "\n",
    "# Attach the function to a class method\n",
    "RecommendationEngine.get_ratings_for_movie_ids = get_ratings_for_movie_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Blueprint\n",
    "main = Blueprint('main', __name__)\n",
    " \n",
    "import json\n",
    "#from engine import RecommendationEngine\n",
    " \n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    " \n",
    "from flask import Flask, request\n",
    " \n",
    "@main.route(\"/<int:user_id>/ratings/top/<int:count>\", methods=[\"GET\"])\n",
    "def top_ratings(user_id, count):\n",
    "    logger.debug(\"User %s TOP ratings requested\", user_id)\n",
    "    top_ratings = recommendation_engine.get_top_ratings(user_id,count)\n",
    "    return json.dumps(top_ratings)\n",
    " \n",
    "@main.route(\"/<int:user_id>/ratings/<int:movie_id>\", methods=[\"GET\"])\n",
    "def movie_ratings(user_id, movie_id):\n",
    "    logger.debug(\"User %s rating requested for movie %s\", user_id, movie_id)\n",
    "    ratings = recommendation_engine.get_ratings_for_movie_ids(user_id, [movie_id])\n",
    "    return json.dumps(ratings)\n",
    " \n",
    "@main.route(\"/<int:user_id>/ratings\", methods = [\"POST\"])\n",
    "def add_ratings(user_id):\n",
    "    # get the ratings from the Flask POST request object\n",
    "    ratings_list = request.form.keys()[0].strip().split(\"\\n\")\n",
    "    ratings_list = map(lambda x: x.split(\",\"), ratings_list)\n",
    "    # create a list with the format required by the negine (user_id, movie_id, rating)\n",
    "    ratings = map(lambda x: (user_id, int(x[0]), float(x[1])), ratings_list)\n",
    "    # add them to the model using then engine API\n",
    "    recommendation_engine.add_ratings(ratings)\n",
    " \n",
    "    return json.dumps(ratings)\n",
    " \n",
    "def create_app(spark_context, movie, ratings):\n",
    "    global recommendation_engine \n",
    " \n",
    "    recommendation_engine = RecommendationEngine(spark_context, movie, ratings)    \n",
    "    \n",
    "    app = Flask(__name__)\n",
    "    app.register_blueprint(main)\n",
    "    return app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting up the Recommendation Engine: \n",
      "INFO:__main__:Counting movie ratings...\n",
      "INFO:__main__:Training the ALS model...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f7f29498fe45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mnewRatingDf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratingdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratingdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'movieId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mapp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_app\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovieDf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewRatingDf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m# start web server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-47c7c82f096b>\u001b[0m in \u001b[0;36mcreate_app\u001b[0;34m(spark_context, movie, ratings)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mrecommendation_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mrecommendation_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRecommendationEngine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mapp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-cee1122e5e5e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sc, movie, ratings)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m#self.iterations = 10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m#self.regularization_parameter = 0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-cee1122e5e5e>\u001b[0m in \u001b[0;36m__train_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Evaluate the model by computing the RMSE on the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n\u001b[1;32m     45\u001b[0m                                         predictionCol=\"prediction\")\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import time, sys, cherrypy, os\n",
    "from paste.translogger import TransLogger\n",
    "#from app import create_app\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import pyspark\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, DoubleType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, concat, lit\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    " \n",
    "def init_spark_context():\n",
    "    # load spark context\n",
    "    #spark = SparkSession.builder.getOrCreate()\n",
    "    MAX_MEMORY = \"5g\"\n",
    "    conf = SparkConf().setAll([(\"spark.app.name\", \"Spark_Processor\"), (\"spark.redis.port\", \"6379\"), \n",
    "                                      (\"spark.jars\", \"spark-redis-branch-2.4/target/spark-redis_2.11-2.5.0-SNAPSHOT-jar-with-dependencies.jar\"), \n",
    "                                      (\"spark.executor.memory\", MAX_MEMORY), (\"spark.driver.memory\", MAX_MEMORY), \n",
    "                                      (\"spark.memory.fraction\", \"0.6\")])\n",
    "    sc = SparkContext(conf=conf)\n",
    "    #conf = SparkConf().setAppName(\"movie_recommendation-server\")\n",
    "    # IMPORTANT: pass aditional Python modules to each worker\n",
    "    #sc = SparkContext(conf=conf, pyFiles=['engine.py', 'app.py'])\n",
    " \n",
    "    return sc\n",
    " \n",
    "def run_server(app):\n",
    " \n",
    "    # Enable WSGI access logging via Paste\n",
    "    app_logged = TransLogger(app)\n",
    " \n",
    "    # Mount the WSGI callable object (app) on the root directory\n",
    "    cherrypy.tree.graft(app_logged, '/')\n",
    " \n",
    "    # Set the configuration of the web server\n",
    "    cherrypy.config.update({\n",
    "        'engine.autoreload.on': True,\n",
    "        'log.screen': True,\n",
    "        'server.socket_port': 5432,\n",
    "        'server.socket_host': '0.0.0.0'\n",
    "    })\n",
    " \n",
    "    # Start the CherryPy WSGI web server\n",
    "    cherrypy.engine.start()\n",
    "    cherrypy.engine.block()\n",
    " \n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    # Init spark context and load libraries\n",
    "    sc = init_spark_context()\n",
    "    spark = SparkSession.builder.config(conf = sc.getConf()).getOrCreate()\n",
    "    #dataset_path = os.path.join('datasets', 'ml-latest')\n",
    "    read_moviedf = spark.read.format(\"org.apache.spark.sql.redis\").option(\"table\", \"movie\").option(\"key.column\", \"title\").load()\n",
    "    movieDf = read_moviedf.sort(\"title\")\n",
    "    datasets_path = os.path.join('..','movie_recommendation_system', 'datasets')\n",
    "    complete_ratings_file = os.path.join(datasets_path, 'ml-latest', 'ratings.csv')\n",
    "    ratingschema = StructType()\\\n",
    "        .add(\"userId\", IntegerType(), True)\\\n",
    "        .add(\"movieId\", IntegerType(), True)\\\n",
    "        .add(\"rating\", DoubleType(), True)\\\n",
    "        .add(\"timeStamp\", IntegerType(), True)\n",
    "    '''\n",
    "    tagsschema = StructType()\\\n",
    "        .add(\"userId\", IntegerType(), True)\\\n",
    "        .add(\"movieId\", IntegerType(), True)\\\n",
    "        .add(\"tag\", StringType(), True)\\\n",
    "        .add(\"timeStamp\", IntegerType(), True)\n",
    "    linkschema = StructType()\\\n",
    "        .add(\"movieId\", IntegerType(), True)\\\n",
    "        .add(\"IMDBID\", IntegerType(), True)\\\n",
    "        .add(\"TMDBID\", IntegerType(), True)\n",
    "    '''\n",
    "    ratingdf = spark.read.format(\"csv\")\\\n",
    "        .option(\"header\",True)\\\n",
    "        .schema(ratingschema)\\\n",
    "        .load(complete_ratings_file)\n",
    "    '''\n",
    "    tagdf = spark.read.format(\"csv\")\\\n",
    "        .option(\"header\",True)\\\n",
    "        .schema(tagsschema)\\\n",
    "        .load(tags_file)\n",
    "    linkdf = spark.read.format(\"csv\")\\\n",
    "        .option(\"header\",True)\\\n",
    "        .schema(linkschema)\\\n",
    "        .load(links_file)\n",
    "    '''\n",
    "    #moviedf = movie.drop(\"genres\")\n",
    "    #genredf = movie.drop(\"title\")\n",
    "    #userdf = ratingdf.drop(\"movieId\", \"rating\", \"timeStamp\")\n",
    "    #userdf = userdf.select('userId').distinct()\n",
    "    ratingdf = ratingdf.drop(\"timestamp\")\n",
    "    ratingdf = ratingdf.withColumn(\"key\", (concat(lit(\"User ID: \"),col(\"userId\"),lit(\", Movie ID: \"),col(\"movieID\"))))\n",
    "    ratingdf = ratingdf.select(\"key\", \"userId\", \"movieId\", \"rating\")\n",
    "    \n",
    "    import pyspark.sql.functions as f\n",
    "    my_list = movieDf.select(f.collect_list('movieId')).first()[0]\n",
    "    newRatingDf = ratingdf.filter(ratingdf['movieId'].isin(my_list))\n",
    "    \n",
    "    app = create_app(sc, movieDf, newRatingDf)\n",
    " \n",
    "    # start web server\n",
    "    run_server(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
